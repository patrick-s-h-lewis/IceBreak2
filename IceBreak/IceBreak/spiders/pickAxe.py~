# -*- coding: utf-8 -*-
import scrapy
import IceBreak.IceBreakTools as ibt
from IceBreak.items import IcebreakItem
import IceBreak.Cubes as cubes 


class PickaxeSpider(scrapy.Spider):
    name = "pickAxe"
    allowed_domains = []
    start_urls = []
    thresholds = {
        "similarity_threshold": 0.6,
        "node_threshold": 50,
        "average_similarity_threshold":0.7,
        "proportion_threshold":0.7
    }

    
    def __init__(self, web_record,*args,**kwargs):
        super(PickaxeSpider, self).__init__(*args, **kwargs)
        self.thresholds = web_record['thresholds']
        self.allowed_domains = web_record['domain']
        self.start_urls = web_record['url']
        self.xp = cubes.main(web_record['url'])

    def parse(self, response):
        r = response
        (layer,sims) = ibt.layer_report(r,self.thresholds)
        while not layer:
            r = ibt.select_cube(r)
            (layer,sims) = ibt.layer_report(r,self.thresholds)
        #ibt.serve_drink(r,sims,self.thresholds)
        [(yield a) for a in self.serve_drink(r,sims)]

    def serve_drink(self,r,sims):
        '''
        consume the children of r, processing only those with high enough similarity in "sims"
        '''
        items = []
        print("i made it")
        cubes = r.xpath("*")
        for ind in range(len(cubes)):
            if sims[ind]>=self.thresholds["similarity_threshold"]:
    	        print("*"*10+"Recording Record number: "+str(ind)+"*"*10)
    	        item = IcebreakItem()
    	        item["links"] = cubes[ind].xpath(".//@href").extract()
    	        item["title"] = "NOT IMPLEMENTED"
    	        item["authors"] = "NOT IMPLEMENTED"
    	        #item["free_text"] = "".join(cubes[ind].xpath("descendant::text()").extract())
    	        item["free_text"] = cubes[ind].xpath("string(.)").extract()
    	        items.append(item)
    	return items